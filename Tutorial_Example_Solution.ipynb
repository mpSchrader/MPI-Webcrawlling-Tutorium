{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Webcrawling Tutorium (Solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to web crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low Level Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import json\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_url = 'https://techcrunch.com'\n",
    "number_of_pages = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_urls(page):\n",
    "    a_s = page.find_all('a', {'class': 'read-more'})\n",
    "    \n",
    "    hrefs = []\n",
    "    for a in a_s:\n",
    "        hrefs.append(a.attrs['href'])\n",
    "        \n",
    "    return hrefs\n",
    "\n",
    "\n",
    "def get_article_info(url, delay=1):\n",
    "    \n",
    "    # Wait for delay seconds to crawl the next page\n",
    "    time.sleep(delay)\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print('Error getting page {} status_code:{}'.format(url, response.status_code))\n",
    "        return {}\n",
    "    \n",
    "    # Converting raw response text to usable BeautifulSoup\n",
    "    page = bs4.BeautifulSoup(response.text, \"lxml\")\n",
    "    \n",
    "    # Exctract Information\n",
    "    title = page.find('h1', {'class': 'tweet-title'}).text\n",
    "    \n",
    "    authors_raw = page.find_all('a', {'rel': 'author'})\n",
    "    authors = [author.text for author in authors_raw]\n",
    "    \n",
    "    date = page.find('time').attrs['datetime']\n",
    "    \n",
    "    tags_raw = page.find_all('div', {'class': 'acc-handle'})\n",
    "    tags = [tag.get_text(strip=True) for tag in tags_raw if tag.text != 'Popular Posts']\n",
    "    \n",
    "    text = page.find('div', {'class': 'text'}).get_text(strip=True)\n",
    "    \n",
    "    # Combine all information in one set\n",
    "    article = {\n",
    "        'title': title,\n",
    "        'url': url,\n",
    "        'date': date,\n",
    "        'authors': authors,\n",
    "        'tags': tags,\n",
    "        'text': text\n",
    "    }\n",
    "    \n",
    "    return article\n",
    "\n",
    "\n",
    "def get_next_url(page, base_url):\n",
    "    \n",
    "    list_item = page.find('li', {'class': 'next'})\n",
    "    href = list_item.find('a').attrs['href']\n",
    "    \n",
    "    url = base_url + href\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling: https://techcrunch.com\n",
      "Crawling: https://techcrunch.com/page/2\n",
      "Crawling: https://techcrunch.com/page/3\n",
      "Error for article: https://techcrunch.com/gallery/the-top-smartphones-of-mwc-2018/\n",
      "Finished crawling. Found 58 Articles\n"
     ]
    }
   ],
   "source": [
    "current_url = base_url\n",
    "\n",
    "articles = []\n",
    "for n in range(number_of_pages):\n",
    "    \n",
    "    print('Crawling: {}'.format(current_url))    \n",
    "    response = requests.get(current_url)\n",
    "    \n",
    "    # Simple error handling, just stop execution when no proper response received\n",
    "    if response.status_code != 200:\n",
    "        print('Error getting page {}'.format(current_url))\n",
    "        break\n",
    "        \n",
    "    # Converting raw response text to usable BeautifulSoup\n",
    "    page = bs4.BeautifulSoup(response.text, \"lxml\")\n",
    "    \n",
    "    article_urls = get_article_urls(page)\n",
    "    # Run through all articles and extract the desired information\n",
    "    for url in article_urls:\n",
    "        try:\n",
    "            article_info = get_article_info(url, delay=0.3)\n",
    "        except:\n",
    "            print('Error for article: {}'.format(url))\n",
    "        articles.append(article_info)\n",
    "        \n",
    "    # Find reference to next page listing articles\n",
    "    current_url = get_next_url(page, base_url)\n",
    "    \n",
    "print('Finished crawling. Found {} Articles'.format(len(articles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Josh Constine]</td>\n",
       "      <td>2018-03-02 03:23:27</td>\n",
       "      <td>[SXSW, TechCrunch, Entertainment]</td>\n",
       "      <td>TechCrunch invites you to our annual Crunch By...</td>\n",
       "      <td>Come to TechCrunch’s party and SXSW panels</td>\n",
       "      <td>https://techcrunch.com/2018/03/02/2018-party-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Sarah Perez]</td>\n",
       "      <td>2018-03-02 10:53:10</td>\n",
       "      <td>[iphone apps, storage, iOS apps, Apps, Apps]</td>\n",
       "      <td>These days, home movies aren’t recorded with h...</td>\n",
       "      <td>Air’s app lets you record high-quality home mo...</td>\n",
       "      <td>https://techcrunch.com/2018/03/02/air-lets-you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Jonathan Salama]</td>\n",
       "      <td>2018-03-02 07:45:38</td>\n",
       "      <td>[trucking, Transportation]</td>\n",
       "      <td>Jonathan SalamaContributorJonathan Salama is c...</td>\n",
       "      <td>Blockchain will work in trucking — but only if...</td>\n",
       "      <td>https://techcrunch.com/2018/03/02/blockchain-w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[John Biggs]</td>\n",
       "      <td>2018-03-02 10:22:48</td>\n",
       "      <td>[robots, Gadgets]</td>\n",
       "      <td>Researchers took part in the Ski Robot Challen...</td>\n",
       "      <td>These robotic skiers hit the slopes in style</td>\n",
       "      <td>https://techcrunch.com/2018/03/02/these-electr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Ingrid Lunden, Steve O'Hear]</td>\n",
       "      <td>2018-03-02 03:18:05</td>\n",
       "      <td>[RPA, uipath, Artificial Intelligence]</td>\n",
       "      <td>The initial hype around bots — applications th...</td>\n",
       "      <td>UiPath raising around $120M at $1B+ valuation ...</td>\n",
       "      <td>https://techcrunch.com/2018/03/02/uipath-rpa/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         authors                 date  \\\n",
       "0                [Josh Constine]  2018-03-02 03:23:27   \n",
       "1                  [Sarah Perez]  2018-03-02 10:53:10   \n",
       "2              [Jonathan Salama]  2018-03-02 07:45:38   \n",
       "3                   [John Biggs]  2018-03-02 10:22:48   \n",
       "4  [Ingrid Lunden, Steve O'Hear]  2018-03-02 03:18:05   \n",
       "\n",
       "                                           tags  \\\n",
       "0             [SXSW, TechCrunch, Entertainment]   \n",
       "1  [iphone apps, storage, iOS apps, Apps, Apps]   \n",
       "2                    [trucking, Transportation]   \n",
       "3                             [robots, Gadgets]   \n",
       "4        [RPA, uipath, Artificial Intelligence]   \n",
       "\n",
       "                                                text  \\\n",
       "0  TechCrunch invites you to our annual Crunch By...   \n",
       "1  These days, home movies aren’t recorded with h...   \n",
       "2  Jonathan SalamaContributorJonathan Salama is c...   \n",
       "3  Researchers took part in the Ski Robot Challen...   \n",
       "4  The initial hype around bots — applications th...   \n",
       "\n",
       "                                               title  \\\n",
       "0         Come to TechCrunch’s party and SXSW panels   \n",
       "1  Air’s app lets you record high-quality home mo...   \n",
       "2  Blockchain will work in trucking — but only if...   \n",
       "3       These robotic skiers hit the slopes in style   \n",
       "4  UiPath raising around $120M at $1B+ valuation ...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://techcrunch.com/2018/03/02/2018-party-a...  \n",
       "1  https://techcrunch.com/2018/03/02/air-lets-you...  \n",
       "2  https://techcrunch.com/2018/03/02/blockchain-w...  \n",
       "3  https://techcrunch.com/2018/03/02/these-electr...  \n",
       "4      https://techcrunch.com/2018/03/02/uipath-rpa/  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(articles)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('my_crawled_articles.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
